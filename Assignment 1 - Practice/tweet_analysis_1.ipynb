{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Imports\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "# Warning Imports\n",
    "import warnings     \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Scikit-learn Imports\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Other Imports\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "# Gensim Imports\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# NLTK Imports\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer       # For Stemming\n",
    "from nltk.stem import WordNetLemmatizer   # For Lemmatization\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the objects\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   target  1600000 non-null  int64 \n",
      " 1   ids     1600000 non-null  int64 \n",
      " 2   date    1600000 non-null  object\n",
      " 3   flag    1600000 non-null  object\n",
      " 4   user    1600000 non-null  object\n",
      " 5   text    1600000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/kazanova/sentiment140\n",
    "# -----------------------------------------------------\n",
    "file_path = r\"../Data/tweet_sentiment.csv\"\n",
    "df = pd.read_csv(file_path, delimiter=',', encoding='latin-1', header=None)\n",
    "df.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "display(df.shape)\n",
    "display(df.info())\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stratified Sampling\n",
    "# -------------------\n",
    "df1, _ = sklearn.model_selection.train_test_split(df,test_size=0.9, stratify=df['target'])\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "\n",
    "### <font color = 'red'> **Tokenize** </font>\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>738780</th>\n",
       "      <td>0</td>\n",
       "      <td>2265557168</td>\n",
       "      <td>Sun Jun 21 06:50:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Shayzorz</td>\n",
       "      <td>@aka_maye wish i could be watching it with you...</td>\n",
       "      <td>[@aka_maye wish i could be watching it with yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376608</th>\n",
       "      <td>4</td>\n",
       "      <td>2051774046</td>\n",
       "      <td>Fri Jun 05 22:46:38 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>MzAmezcua02</td>\n",
       "      <td>MY NAME ISNT WILLIS. STUPID ASS BOBO LOL TEE--...</td>\n",
       "      <td>[MY NAME ISNT WILLIS., STUPID ASS BOBO LOL TEE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36211</th>\n",
       "      <td>0</td>\n",
       "      <td>1565577957</td>\n",
       "      <td>Mon Apr 20 07:05:02 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>alealex26</td>\n",
       "      <td>sacrifice, fulfillment and gratitude..my heart...</td>\n",
       "      <td>[sacrifice, fulfillment and gratitude..my hear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499800</th>\n",
       "      <td>4</td>\n",
       "      <td>2070973600</td>\n",
       "      <td>Sun Jun 07 18:36:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>xobreanna</td>\n",
       "      <td>being amused at heidi pratt being a christian ...</td>\n",
       "      <td>[being amused at heidi pratt being a christian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211766</th>\n",
       "      <td>0</td>\n",
       "      <td>1974571090</td>\n",
       "      <td>Sat May 30 13:24:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>frost914</td>\n",
       "      <td>Last Jay Leno episode was good, can't wait for...</td>\n",
       "      <td>[Last Jay Leno episode was good, can't wait fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target         ids                          date      flag  \\\n",
       "738780        0  2265557168  Sun Jun 21 06:50:33 PDT 2009  NO_QUERY   \n",
       "1376608       4  2051774046  Fri Jun 05 22:46:38 PDT 2009  NO_QUERY   \n",
       "36211         0  1565577957  Mon Apr 20 07:05:02 PDT 2009  NO_QUERY   \n",
       "1499800       4  2070973600  Sun Jun 07 18:36:59 PDT 2009  NO_QUERY   \n",
       "211766        0  1974571090  Sat May 30 13:24:20 PDT 2009  NO_QUERY   \n",
       "\n",
       "                user                                               text  \\\n",
       "738780      Shayzorz  @aka_maye wish i could be watching it with you...   \n",
       "1376608  MzAmezcua02  MY NAME ISNT WILLIS. STUPID ASS BOBO LOL TEE--...   \n",
       "36211      alealex26  sacrifice, fulfillment and gratitude..my heart...   \n",
       "1499800    xobreanna  being amused at heidi pratt being a christian ...   \n",
       "211766      frost914  Last Jay Leno episode was good, can't wait for...   \n",
       "\n",
       "                                            tokenized_text  \n",
       "738780   [@aka_maye wish i could be watching it with yo...  \n",
       "1376608  [MY NAME ISNT WILLIS., STUPID ASS BOBO LOL TEE...  \n",
       "36211    [sacrifice, fulfillment and gratitude..my hear...  \n",
       "1499800  [being amused at heidi pratt being a christian...  \n",
       "211766   [Last Jay Leno episode was good, can't wait fo...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1['tokenized_text'] = df1['text'].apply(nltk.sent_tokenize)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_1(sentence):\n",
    "    corpus = []\n",
    "    for i in range(len(sentence)):\n",
    "        review = re.sub('[^a-zA-Z]',' ', sentence[i])\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        review = [lemmatizer.lemmatize(word) for word in review if not word in set(stopwords)]\n",
    "        review = \" \".join(review)\n",
    "        corpus.append(review)\n",
    "    return corpus\n",
    "\n",
    "df1['preprocessed_1'] = df1['tokenized_text'].apply(pre_processing_1)   \n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = [['word', 'embeddings', 'are', 'useful'],\n",
    "             ['word', 'embeddings', 'capture', 'semantic', 'relationships'],\n",
    "             ['gensim', 'is', 'a', 'library', 'for', 'Word2Vec']]\n",
    "model = Word2Vec(s1, vector_size=100, window=5, min_count=1, workers=4)\n",
    "word_embedding = model.wv['word']\n",
    "print(word_embedding[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
